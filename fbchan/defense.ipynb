{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76351cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import tqdm\n",
    "from resnet1d import Resnet34\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90edfeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_ori():\n",
    "    def __init__(self,data_path,label_path, selected_class=None):\n",
    "        # self.root = root\n",
    "        self.data_path = data_path\n",
    "        self.label_path = label_path\n",
    "        self.selected_class = selected_class\n",
    "        self.dataset,self.labelset= self.build_dataset()\n",
    "        self.length = self.dataset.shape[0]\n",
    "        # self.minmax_normalize()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        step = self.dataset[idx,:]\n",
    "        step = torch.unsqueeze(step, 0)\n",
    "        # target = self.label[idx]\n",
    "        target = self.labelset[idx]\n",
    "        # target = torch.unsqueeze(target, 0)# only one class\n",
    "        return step, target\n",
    "\n",
    "    def build_dataset(self):\n",
    "        '''get dataset of signal'''\n",
    "\n",
    "        dataset = np.load(self.data_path)\n",
    "        labelset = np.load(self.label_path)\n",
    "            \n",
    "        if self.selected_class is not None:\n",
    "            dataset = dataset[labelset == self.selected_class]\n",
    "            labelset = labelset[labelset == self.selected_class]\n",
    "\n",
    "        # dataset,labelset = shuffle(dataset,labelset)\n",
    "        dataset = torch.from_numpy(dataset)\n",
    "        labelset = torch.from_numpy(labelset)\n",
    "\n",
    "        return dataset,labelset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "05f4a561",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_backdoor():\n",
    "    def __init__(self,data_path,label_path,backdoor_perc,target_class,ret_attack_only=False,bd_labelset=True,sample_ratio=None, trigger=None, mask=None):\n",
    "        # self.root = root\n",
    "        self.data_path = data_path\n",
    "        self.label_path = label_path\n",
    "        self.backdoor_perc = backdoor_perc\n",
    "        self.target_class = target_class\n",
    "        self.ret_attack_only = ret_attack_only\n",
    "        self.bd_labelset = bd_labelset\n",
    "        self.sample_ratio = sample_ratio\n",
    "        self.trigger = trigger\n",
    "        self.mask = mask\n",
    "        self.dataset,self.labelset= self.build_dataset()\n",
    "        self.length = self.dataset.shape[0]\n",
    "        # self.minmax_normalize()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        step = self.dataset[idx,:]\n",
    "        step = torch.unsqueeze(step, 0)\n",
    "        target = self.labelset[idx]\n",
    "        return step, target\n",
    "    \n",
    "    def apply_trigger(self, dataset, labelset):\n",
    "        \n",
    "\n",
    "        print('Apply trigger', np.unique(labelset, return_counts=True), flush=True)\n",
    "        trigger_class = 1 - self.target_class\n",
    "        trigger_class_idx = np.where(labelset == trigger_class)[0]\n",
    "        trigger_sample_idx = trigger_class_idx[np.random.choice(len(trigger_class_idx), int(self.backdoor_perc * len(trigger_class_idx)), replace=False)]\n",
    "        dataset_bd = dataset.copy()\n",
    "        labelset_bd = labelset.copy()\n",
    "        for idx in tqdm.tqdm(trigger_sample_idx):\n",
    "            if self.mask is not None and self.trigger is not None:\n",
    "                dataset_bd[idx] = (1 - self.mask[None, :]) * dataset_bd[idx] + self.mask[None, :] * trigger \n",
    "            if self.bd_labelset:\n",
    "                labelset_bd[idx] = self.target_class\n",
    "        \n",
    "        if self.ret_attack_only:\n",
    "            return dataset_bd[trigger_sample_idx], labelset_bd[trigger_sample_idx]\n",
    "        else:\n",
    "            return dataset_bd, labelset_bd\n",
    "\n",
    "    def build_dataset(self):\n",
    "        '''get dataset of signal'''\n",
    "\n",
    "        dataset = np.load(self.data_path)\n",
    "        labelset = np.load(self.label_path)\n",
    "\n",
    "        if self.sample_ratio is not None:\n",
    "            indices = np.random.choice(len(dataset), int(self.sample_ratio * len(dataset)), replace=False)\n",
    "            dataset, labelset = dataset[indices], labelset[indices]\n",
    "            \n",
    "        if self.backdoor_perc > 0:\n",
    "            dataset, labelset = self.apply_trigger(dataset, labelset)\n",
    "\n",
    "        dataset = torch.from_numpy(dataset)\n",
    "        labelset = torch.from_numpy(labelset)\n",
    "\n",
    "        return dataset,labelset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8319017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, target_label, testloader, param):\n",
    "    print(\"Processing label: {}\".format(target_label))\n",
    "\n",
    "    signal_length = param[\"signal_length\"]\n",
    "    trigger = torch.rand((signal_length), requires_grad=True)\n",
    "    trigger = trigger.to(device).detach().requires_grad_(True)\n",
    "    mask = torch.rand((signal_length), requires_grad=True)\n",
    "    mask = mask.to(device).detach().requires_grad_(True)\n",
    "\n",
    "    Epochs = param[\"Epochs\"]\n",
    "    lamda = param[\"lamda\"]\n",
    "\n",
    "    min_norm = np.inf\n",
    "    min_norm_count = 0\n",
    "\n",
    "    criterion = CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam([{\"params\": trigger},{\"params\": mask}],lr=0.005)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    for epoch in range(Epochs):\n",
    "        norm = 0.0\n",
    "        loss_list = []\n",
    "        for signal, _ in tqdm.tqdm(testloader, desc='Epoch %3d' % (epoch + 1)):\n",
    "            optimizer.zero_grad()\n",
    "            signal = signal.to(device)\n",
    "            \n",
    "            trojan_signal = (1 - torch.unsqueeze(mask, dim=0)) * signal + torch.unsqueeze(mask, dim=0) * trigger\n",
    "            trojan_signal = trojan_signal.float()\n",
    "            _, y_pred = model(trojan_signal)\n",
    "            y_target = torch.full((y_pred.size(0),), target_label, dtype=torch.long).to(device)\n",
    "            \n",
    "            loss = criterion(y_pred, y_target) + lamda * torch.sum(torch.abs(mask))\n",
    "            loss_list.append(loss.detach().cpu().numpy())\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # figure norm\n",
    "            with torch.no_grad():\n",
    "                # 防止trigger和norm越界\n",
    "                torch.clip_(trigger, 0, 1)\n",
    "                torch.clip_(mask, 0, 1)\n",
    "                norm = torch.sum(torch.abs(mask))\n",
    "                \n",
    "        print(\"loss: \", np.mean(loss_list))\n",
    "        \n",
    "        print(\"norm: {}\".format(norm))\n",
    "\n",
    "        # to early stop\n",
    "        if norm < min_norm:\n",
    "            min_norm = norm\n",
    "            min_norm_count = 0\n",
    "        else:\n",
    "            min_norm_count += 1\n",
    "\n",
    "        if min_norm_count > 30:\n",
    "            break\n",
    "\n",
    "    return trigger.cpu(), mask.cpu()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f4d7f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_engineer():\n",
    "    param = {\n",
    "        \"Epochs\": 5,\n",
    "        \"batch_size\": 64,\n",
    "        \"lamda\": 0.01,\n",
    "        \"num_classes\": 2,\n",
    "        \"signal_length\": 2400,\n",
    "        \"trigger_size\":100\n",
    "    }\n",
    "    \n",
    "    MODEL_PATH = '/home/users/bc272/ahahahaha/backdoor/saved_models/res34_epoch_30_ppglr_0.0001_BDPERC_0.1_0_1_/PPG_best_0.pt'\n",
    "    state_dict = torch.load(MODEL_PATH) \n",
    "    \n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:] #remove 'module'\n",
    "        new_state_dict[name] = v\n",
    "\n",
    "    state_dict = new_state_dict\n",
    "    \n",
    "    model = Resnet34().cuda()\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    data_folder = '/usr/xtmp/zg78/stanford_dataset/'\n",
    "    \n",
    "    # \n",
    "    test_dataset = Dataset_ori(data_folder+'testx_accpt_clean.npy', data_folder+'testy_af_accpt_clean.npy')\n",
    "    testloader = DataLoader(test_dataset, batch_size=2500, shuffle=False, num_workers=0)\n",
    "    \n",
    "\n",
    "    norm_list = []\n",
    "    trigger_list = []\n",
    "    mask_list = []\n",
    "    for label in range(param[\"num_classes\"]):\n",
    "        test_dataset = Dataset_ori(data_folder+'testx_accpt_clean.npy', data_folder+'testy_af_accpt_clean.npy',selected_class = 1- label)\n",
    "        testloader = DataLoader(test_dataset, batch_size=2500, shuffle=False, num_workers=0)\n",
    "        \n",
    "        trigger, mask = train(model, label, testloader, param)\n",
    "        norm_list.append(mask.sum().item())\n",
    "\n",
    "        trigger = trigger.cpu().detach().numpy()\n",
    "        trigger_list.append(trigger)\n",
    "        \n",
    "        mask = mask.cpu().detach().numpy()\n",
    "        mask_list.append(mask)\n",
    "        \n",
    "        \n",
    "        print(\"class:\", label)\n",
    "        print(\"trigger:\", trigger)\n",
    "        print(\"mask:\", mask)\n",
    "\n",
    "    print(norm_list)\n",
    "    return norm_list, trigger_list, mask_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0bdd17ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unlearning(target_class, trigger, mask):\n",
    "    param = {\n",
    "        \"Epochs\": 2,\n",
    "        \"batch_size\": 1280,\n",
    "        \"signal_length\": 2400,\n",
    "        \"sample_ratio\": 0.1,\n",
    "        \"backdoor_percentage\": 0.2,\n",
    "        \"learning_rate\": 0.01\n",
    "    }\n",
    "    \n",
    "    MODEL_PATH = '/home/users/bc272/ahahahaha/backdoor/saved_models/res34_epoch_30_ppglr_0.0001_BDPERC_0.1_0_1_/PPG_best_0.pt'\n",
    "    state_dict = torch.load(MODEL_PATH) \n",
    "    \n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:] #remove 'module'\n",
    "        new_state_dict[name] = v\n",
    "\n",
    "    state_dict = new_state_dict\n",
    "    \n",
    "    model = Resnet34().cuda()\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    data_folder = '/usr/xtmp/zg78/stanford_dataset/'\n",
    "    train_dataset = Dataset_backdoor(data_folder+'trainx_accpt_clean.npy', data_folder+'trainy_af_accpt_clean.npy', backdoor_perc=param[\"backdoor_percentage\"], target_class=target_class, sample_ratio=param[\"sample_ratio\"], bd_labelset=False)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=param[\"batch_size\"], shuffle=True)\n",
    "    model.train()\n",
    "    \n",
    "    criterion = CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = param[\"learning_rate\"])\n",
    "    loss_list = []\n",
    "    for epoch in range(param[\"Epochs\"]):\n",
    "        for signal, y_target in tqdm.tqdm(train_loader, desc='Epoch %3d' % (epoch + 1)):\n",
    "            optimizer.zero_grad()\n",
    "            signal, y_target = signal.float().to(device), y_target.long().to(device)\n",
    "            _, y_pred = model(signal)\n",
    "            loss = criterion(y_pred, y_target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_list.append(loss.detach().cpu().numpy())\n",
    "        print(np.mean(loss_list))\n",
    "    torch.save(model, \"finetune_model.pt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33b91e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1: 100%|██████████| 1/1 [00:00<00:00, 34.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  12.159385\n",
      "norm: 1203.9737548828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   2: 100%|██████████| 1/1 [00:00<00:00, 35.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  12.039738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm: 1192.08837890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   3: 100%|██████████| 1/1 [00:00<00:00, 40.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  11.920883\n",
      "norm: 1180.274169921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   4: 100%|██████████| 1/1 [00:00<00:00, 38.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  11.802741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm: 1168.537109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   5: 100%|██████████| 1/1 [00:00<00:00, 40.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  11.68537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm: 1156.8642578125\n",
      "class: 0\n",
      "trigger: [0.38642547 0.221005   0.9088861  ... 0.78015774 0.49868107 0.62223184]\n",
      "mask: [0.735913   0.45221716 0.35121697 ... 0.30732405 0.         0.8255901 ]\n",
      "Processing label: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1: 100%|██████████| 2/2 [00:00<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  28.914509\n",
      "norm: 1200.5091552734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   2: 100%|██████████| 2/2 [00:00<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  25.578827\n",
      "norm: 1193.224609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   3: 100%|██████████| 2/2 [00:00<00:00,  4.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  22.818312\n",
      "norm: 1186.093994140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   4: 100%|██████████| 2/2 [00:00<00:00,  4.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  20.482456\n",
      "norm: 1179.0478515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   5: 100%|██████████| 2/2 [00:00<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  18.474396\n",
      "norm: 1172.145751953125\n",
      "class: 1\n",
      "trigger: [0.04041995 0.21091048 0.29284626 ... 0.425403   0.47919703 0.55639017]\n",
      "mask: [1.         0.28671545 0.94942474 ... 0.7213114  0.79479516 0.11647457]\n",
      "[1156.8642578125, 1172.1458740234375]\n",
      "Apply trigger (array([0., 1.]), array([52831, 30341]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6068/6068 [00:00<00:00, 2901394.97it/s]\n",
      "Epoch   1: 100%|██████████| 65/65 [00:12<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39326683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   2: 100%|██████████| 65/65 [00:12<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28634477\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    norm_list, trigger_list, mask_list = reverse_engineer()\n",
    "    target_class = np.argmin(norm_list)\n",
    "    unlearning(target_class, trigger_list[target_class], mask_list[target_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccd5683",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, t in enumerate(trigger_list):\n",
    "    plt.ylim(0, 1)\n",
    "    plt.plot(trigger_list[i] * mask_list[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b01f5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94400764, 0.7164599 , 0.92285734, ..., 0.25152296, 0.8607536 ,\n",
       "       0.4635501 ], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigger_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee57b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
