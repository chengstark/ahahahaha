JOB START
Mon Mar  6 17:12:28 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:5E:00.0 Off |                  N/A |
| 37%   30C    P0    48W / 250W |      0MiB / 11019MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
BATCH_SIZE 1280
NUM_EPOCHS 30
device cuda
PPG_LR 1e-05
subset 0
COMMENT bs=2500
MODEL_FOLDER res34_epoch_30_ppglr_1e-05_bs=2500
Creating datasets
Dataset finished
Epoch 0 training...
/home/users/zg78/_conda/envs/base_torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
	[TRAIN] Epoch 0 Batch 0/650 Loss: 0.7334171533584595, 	PPG F1: 0.3083421330517423, 	Batch Avg-T: 0:00:01.898689
	[TRAIN] Epoch 0 Batch 100/650 Loss: 0.6049487608494145, 	PPG F1: 0.5758660503382762, 	Batch Avg-T: 0:00:00.206377
	[TRAIN] Epoch 0 Batch 200/650 Loss: 0.5454606396048817, 	PPG F1: 0.6166914395709309, 	Batch Avg-T: 0:00:00.198655
	[TRAIN] Epoch 0 Batch 300/650 Loss: 0.49684227790151325, 	PPG F1: 0.6530222170937235, 	Batch Avg-T: 0:00:00.196316
	[TRAIN] Epoch 0 Batch 400/650 Loss: 0.45972958251722434, 	PPG F1: 0.681613828663631, 	Batch Avg-T: 0:00:00.195188
	[TRAIN] Epoch 0 Batch 500/650 Loss: 0.43095431225504466, 	PPG F1: 0.704350630537117, 	Batch Avg-T: 0:00:00.194660
	[TRAIN] Epoch 0 Batch 600/650 Loss: 0.4081360540552663, 	PPG F1: 0.7222397789660447, 	Batch Avg-T: 0:00:00.194425
[TRAIN] Epoch 0 Loss: 0.3984222536362135,             	PPG F1: 0.7299407237299523
Time - 0:02:06.389355
/home/users/zg78/_conda/envs/base_torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[VAL] Epoch 0 Loss: 0.6172080202678206, 	PPG F1: 0.25778098661183746
Epoch 0 finished. t = 0:02:12.810451
Saving...


Epoch 1 training...
/home/users/zg78/_conda/envs/base_torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
	[TRAIN] Epoch 1 Batch 0/650 Loss: 0.26838040351867676, 	PPG F1: 0.8174692049272118, 	Batch Avg-T: 0:00:01.561314
	[TRAIN] Epoch 1 Batch 100/650 Loss: 0.26165479406861974, 	PPG F1: 0.8365878768499208, 	Batch Avg-T: 0:00:00.207825
	[TRAIN] Epoch 1 Batch 200/650 Loss: 0.2521452220221657, 	PPG F1: 0.8435591403978981, 	Batch Avg-T: 0:00:00.201219
	[TRAIN] Epoch 1 Batch 300/650 Loss: 0.24592245897383389, 	PPG F1: 0.847733776245017, 	Batch Avg-T: 0:00:00.199084
	[TRAIN] Epoch 1 Batch 400/650 Loss: 0.23999681734384742, 	PPG F1: 0.8518737403168612, 	Batch Avg-T: 0:00:00.198029
	[TRAIN] Epoch 1 Batch 500/650 Loss: 0.2347681448904578, 	PPG F1: 0.8556558023151805, 	Batch Avg-T: 0:00:00.197595
	[TRAIN] Epoch 1 Batch 600/650 Loss: 0.23031713368492, 	PPG F1: 0.858830027789348, 	Batch Avg-T: 0:00:00.197376
[TRAIN] Epoch 1 Loss: 0.22824259764873064,             	PPG F1: 0.860075786546475
Time - 0:02:08.316536
/home/users/zg78/_conda/envs/base_torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[VAL] Epoch 1 Loss: 0.5268987990359482, 	PPG F1: 0.30054259742090056
Epoch 1 finished. t = 0:02:14.754872
Saving...


Epoch 2 training...
/home/users/zg78/_conda/envs/base_torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
	[TRAIN] Epoch 2 Batch 0/650 Loss: 0.18908390402793884, 	PPG F1: 0.8812095032397408, 	Batch Avg-T: 0:00:01.602830
	[TRAIN] Epoch 2 Batch 100/650 Loss: 0.19385152804379416, 	PPG F1: 0.88236861403838, 	Batch Avg-T: 0:00:00.209536
	[TRAIN] Epoch 2 Batch 200/650 Loss: 0.19287714154566105, 	PPG F1: 0.8837865489823659, 	Batch Avg-T: 0:00:00.202750
	[TRAIN] Epoch 2 Batch 300/650 Loss: 0.19056852444065767, 	PPG F1: 0.8851643303990409, 	Batch Avg-T: 0:00:00.200536
	[TRAIN] Epoch 2 Batch 400/650 Loss: 0.18881991925530897, 	PPG F1: 0.8863421997322929, 	Batch Avg-T: 0:00:00.199453
	[TRAIN] Epoch 2 Batch 500/650 Loss: 0.1865074754415634, 	PPG F1: 0.8880025663677209, 	Batch Avg-T: 0:00:00.198816
	[TRAIN] Epoch 2 Batch 600/650 Loss: 0.18470592273650271, 	PPG F1: 0.8890782716934139, 	Batch Avg-T: 0:00:00.198392
[TRAIN] Epoch 2 Loss: 0.18387557733517426,             	PPG F1: 0.8896338952670927
Time - 0:02:08.910512
/home/users/zg78/_conda/envs/base_torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[VAL] Epoch 2 Loss: 0.6290575996718695, 	PPG F1: 0.3015762043981187
Epoch 2 finished. t = 0:02:15.388034


Epoch 3 training...
/home/users/zg78/_conda/envs/base_torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
	[TRAIN] Epoch 3 Batch 0/650 Loss: 0.17559561133384705, 	PPG F1: 0.8818897637795275, 	Batch Avg-T: 0:00:01.661383
	[TRAIN] Epoch 3 Batch 100/650 Loss: 0.16962646139730322, 	PPG F1: 0.8996880856445675, 	Batch Avg-T: 0:00:00.210138
	[TRAIN] Epoch 3 Batch 200/650 Loss: 0.1654937050087535, 	PPG F1: 0.9019731893910401, 	Batch Avg-T: 0:00:00.203033
	[TRAIN] Epoch 3 Batch 300/650 Loss: 0.16377836250486563, 	PPG F1: 0.9027545112936224, 	Batch Avg-T: 0:00:00.200701
	[TRAIN] Epoch 3 Batch 400/650 Loss: 0.16291990852043814, 	PPG F1: 0.9032845798057776, 	Batch Avg-T: 0:00:00.199559
	[TRAIN] Epoch 3 Batch 500/650 Loss: 0.16164531689620543, 	PPG F1: 0.9042027089093799, 	Batch Avg-T: 0:00:00.198889
	[TRAIN] Epoch 3 Batch 600/650 Loss: 0.16051095923697095, 	PPG F1: 0.9049834922997484, 	Batch Avg-T: 0:00:00.198437
[TRAIN] Epoch 3 Loss: 0.15993750112561078,             	PPG F1: 0.9053577295449928
Time - 0:02:08.934416
/home/users/zg78/_conda/envs/base_torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[VAL] Epoch 3 Loss: 0.49156457103707596, 	PPG F1: 0.33599335936763064
Epoch 3 finished. t = 0:02:15.436383
Saving...


Epoch 4 training...
/home/users/zg78/_conda/envs/base_torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
	[TRAIN] Epoch 4 Batch 0/650 Loss: 0.14447085559368134, 	PPG F1: 0.9188034188034188, 	Batch Avg-T: 0:00:01.624134
	[TRAIN] Epoch 4 Batch 100/650 Loss: 0.14614425156966293, 	PPG F1: 0.914836831655199, 	Batch Avg-T: 0:00:00.209839
	[TRAIN] Epoch 4 Batch 200/650 Loss: 0.14603251837824113, 	PPG F1: 0.9141714231971868, 	Batch Avg-T: 0:00:00.202975
	[TRAIN] Epoch 4 Batch 300/650 Loss: 0.14506216619497914, 	PPG F1: 0.9148708948713746, 	Batch Avg-T: 0:00:00.200687
	[TRAIN] Epoch 4 Batch 400/650 Loss: 0.14420875371840233, 	PPG F1: 0.9153257115313507, 	Batch Avg-T: 0:00:00.199568
	[TRAIN] Epoch 4 Batch 500/650 Loss: 0.14383186316656732, 	PPG F1: 0.9156074427640805, 	Batch Avg-T: 0:00:00.198926
slurmstepd: error: *** JOB 2916713 ON linux52 CANCELLED AT 2023-03-06T17:25:06 ***
